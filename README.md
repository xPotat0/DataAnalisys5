# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]



Отчет по лабораторной работе #5 выполнил:
- Исмагилов Денис Рустамович
- РИ210945
Отметка о выполнении заданий (заполняется студентом):


| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | # | 60 |
| Задание 2 | # | 20 |
| Задание 3 | # | 20 |


знак "*" - задание выполнено; знак "#" - задание не выполнено;


Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.




## Цель работы
 - Интеграция экономической системы в проект Unity и обучение ML-Agent.


## Задание 1
 - Изменить параметры файла .yaml-агента и определить какие параметры и как влияют на обучение модели.. 

## Ход работы:
Исследуем проект, который нам предоставили. 
 - В модели реализовано передвижение Агента RollerAgent между 
двумя объектами: Target и GoldMine. Модель представляет собой 
упрощенный симулятор добычи ресурсов и их транспортировки.
 - Направление движения Агента определяется переменными скрипт-файла Move.cs в инспекторе свойств:
 - Модель обучения Агента, как и ранее определяется скрипт-файлами, 
импортированными из ml-agents-release_19: Decision Requester и 
Behavior Parameters. 
 - В скрипт-файле Decision Requester устанавливается период 
принятия решения, равный 10. Это значит, что цикл наблюдение-решение-действие-вознаграждение повторяется каждый раз, когда 
агент запрашивает решение. Агенты будут запрашивать решение при 
вызове Agent.RequestDecision(). Через период Decision Period = 10.
Бывают ситуации, когда нужно, чтобы агент запрашивал решения 
самостоятельно через регулярные промежутки времени. В этом 
случае мы можем использовать в коде компонент Decision Requester 
в GameObject агента.
 - Также обратитим внимание на настройки параметров поведения 
агента Behavior Parameters. Здесь Vector Observation определяется 
параметрами: Space Size - длина наблюдения вектора для Агента. 
Stacked Vectors - Количество предыдущих векторных наблюдений, 
которые будут суммироваться и совместно использоваться для 
принятия решений. Другими словами, Vector Observation определяет 
эффективный размер векторного наблюдения, передаваемого в 
политику, составляет: Space Size x Stacked Vectors. 
 - Action (действия) определяют количество одновременных 
непрерывных действий (непрерывные действия — Continuous
Actions), которые может выполнять агент. Дискретные ветви — 
массив целых чисел, определяющий несколько одновременных 
дискретных действий. Значения в массиве Discrete Branches 
соответствуют количеству возможных дискретных значений для 
каждой ветви действия.
 - Скрипт-файл Move.cs описывает поведение при движении Агента. А 
также его вознаграждение и обучение:

|Функция в скрипт-файле Moce.cs|Пояснение работы функции|
|-|-|
|public override void 
CollectObservations(VectorSensor 
sensor)|В этой функции задаются параметры, 
на основе которых обучается Агент 
(сенсоры агента)|
